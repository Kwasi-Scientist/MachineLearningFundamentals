{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow.compat.v1 as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from numpy import unique, argmax\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import Model\n",
    "#import tensorflow_datasets as tfds\n",
    "#import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "#import tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## disable V2 behavior to allow for place holder\n",
    "#tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arg_parser():\n",
    "    parser = argparse.ArgumentParser(description='Build a CNN classifier \\\n",
    "            using MNIST data')\n",
    "    parser.add_argument('--input-dir', dest='input_dir', type=str,\n",
    "            default='./mnist_data', help='Directory for storing data')\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(shape):\n",
    "    data = keras.initializers.TruncatedNormal(shape, stddev=0.1)\n",
    "    return tf.Variable(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biases(shape):\n",
    "    data = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layer(shape):\n",
    "    # Get the weights and biases\n",
    "    W = get_weights(shape)\n",
    "    b = get_biases([shape[-1]])\n",
    "\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1],\n",
    "            padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "            strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if __name__ == '__main__':\n",
    "if __name__ == '__main__' and '__file__' in globals():\n",
    "    args = build_arg_parser().parse_args()\n",
    "    #tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist = input_data.read_data_sets(args.input_dir, one_hot=True)\n",
    "mnist_keras = keras.datasets.mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = mnist_keras\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get Mnist Dataset\n",
    "# #mnist1 = tf.keras.datasets.mnist#.load_data(path='mnist.npz')\n",
    "# batch_size=75\n",
    "# #mnist = tfds.as_numpy(tfds.load(name='mnist', as_supervised=True, batch_size=batch_size))\n",
    "# mnist_train, mnist_test = tfds.load(name='mnist',split=['train','test'], as_supervised=True)#, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_one_hot(feature, label):\n",
    "#     return feature, tf.one_hot(label, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist_train = mnist_train.map(my_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist_train = mnist_train.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## disable V2 behavior to allow for place holder\n",
    "#tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-bda0b2b2be20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# The images are 28x28. Create the input layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#x = tf.placeholder(tf.float32, [None, 784])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# The images are 28x28. Create the input layer\n",
    "#x = tf.placeholder(tf.float32, [None, 784])\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(1)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find shape of x\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape 'x' into a 4D tensor\n",
    "x_image = tf.reshape(x, [-1, 28, 28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Make Model </h3>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3> Make Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "\n",
    "model = keras.Sequential()\n",
    "#define input layer\n",
    "model.add(Flatten(input_shape=(28,28,1)))\n",
    "model.add(Conv2D([5,5,1,32],activation ='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Conv2D([5, 5, 32, 64], activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Dense([7*7*64,1024]))\n",
    "model.add(tf.keras.layers.Reshape([-1,7*7*64]))\n",
    "model.add()\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not interpret activation function identifier: 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-eefaadccfaaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-eefaadccfaaf>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMyCNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_conv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#tf.Variable(tf.truncated_normal([5,5,1,32]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_conv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#Variable(tf.truncated_normal([32]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\activations.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0midentifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m     raise TypeError(\n\u001b[0m\u001b[0;32m    580\u001b[0m         'Could not interpret activation function identifier: {}'.format(\n\u001b[0;32m    581\u001b[0m             identifier))\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not interpret activation function identifier: 5"
     ]
    }
   ],
   "source": [
    "class MyCNN(Model):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.w_conv1 = Dense([5,5,1,32]) #tf.Variable(tf.truncated_normal([5,5,1,32]))\n",
    "        self.b_conv1 = Dense([10])#Variable(tf.truncated_normal([32]))\n",
    "        self.flatten = Flatten(input_shape=(28, 28,1))\n",
    "        self.conv1 = Conv2D([5, 5, 1, 32], activation='relu')\n",
    "        self.pool1= MaxPool2D(self.conv1)\n",
    "        self.conv2 = Conv2D([5,5,32,64])\n",
    "        self.pool2 = MaxPool2D(self.conv2)\n",
    "        self.w_fc1 = Variable(tf.truncated_normal(7*7*63,1024))\n",
    "        self.b_fc1 = Variable(tf.truncated_normal(1024))#Dense([7*7*63, 1024])\n",
    "        self.reshape = Reshape([-1,7*7*64])\n",
    "        self.h_fc1 = Matmul((self.pool2, self.w_fc1)+b_fc1)\n",
    "        self.drop = Dropout(0.2)\n",
    "        self.w_fc2 = Desne([1024, 10])#Variable(tf.truncated_normal(1024,10))\n",
    "        self.b_fc2 = Desne([10])#Variable(tf.truncated_normal(10))#Dense([1024,10])\n",
    "        self.y_conv = Matmul((self.h_fc1, w_fc2)+b_fc2)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.reshape(x)\n",
    "        x = self.h_fc1(x)\n",
    "        x = self.drop(x)\n",
    "        return self.y_conv(x)\n",
    "    \n",
    "model = MyCNN()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "    self.flatten = Flatten()\n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the first convolutional layer\n",
    "W_conv1, b_conv1 = create_layer([5,5,1, 32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolve the image with weight tensor, add the\n",
    "# bias, and then apply the ReLU function\n",
    "h_conv1 = tf.nn.relu(tf.nn.relu(convolution_2d(x_image, W_conv1)+ b_conv1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the max pooling operator\n",
    "h_pool1 = max_pooling(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second convolutional layer\n",
    "W_conv2, b_conv2 = create_layer([5, 5,32,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolve the output of previous layer with the\n",
    "# weight tensor, add the bias, and then apply\n",
    "# the ReLU function\n",
    "h_conv2 = tf.nn.relu(convolution_2d(h_pool1,W_conv2)+b_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the max pooling operator\n",
    "h_pool2 = max_pooling(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fully connected layer\n",
    "W_fc1, b_fc1 = create_layer([7*7*64,1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the output of the previous layer\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1,7*7*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply the output of previous layer by the\n",
    "# weight tensor, add the bias, and then apply\n",
    "# the ReLU function * Use \"tf.matmul\" for matrix multiplication\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Define the dropout layer using a probability placeholder\n",
    "# for all the neurons\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the readout layer (output layer)\n",
    "W_fc2, b_fc2 = create_layer([1024,10])\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "#y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-61e3500dd964>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Define the entropy loss and the optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#placeholder(tf.float32,[None, 10])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_conv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# Define the entropy loss and the optimizer\n",
    "#placeholder(tf.float32,[None, 10])\n",
    "y_loss = tf.placeholder(tf.float32, [None,10])\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(y_conv, y_loss))\n",
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the accuracy computation\n",
    "predicted = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_loss, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:247: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:247: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# Create and run a session\n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.initialize_all_variables()\n",
    "#init = tf.global_variable_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iterator = mnist_train.make_initializable_iterator()\n",
    "# next_element = train_iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the model....\n",
      "Iteration 0 , Accuracy = 0.06666667\n",
      "Iteration 50 , Accuracy = 0.06666667\n",
      "Iteration 100 , Accuracy = 0.06666667\n",
      "Iteration 150 , Accuracy = 0.06666667\n",
      "Iteration 200 , Accuracy = 0.06666667\n",
      "Test accuracy = 0.06666667\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "num_iterations = 210 #21000\n",
    "batch_size = 75\n",
    "#make iterator \n",
    "\n",
    "train_iterator = tf.compat.v1.data.make_initializable_iterator(mnist_train)\n",
    "next_element = train_iterator.get_next()\n",
    "print('\\nTraining the model....')\n",
    "for i in range(num_iterations):\n",
    "    #for next_element in mnist_train:\n",
    "    sess.run(train_iterator.initializer)\n",
    "    batch_x, batch_y = sess.run(next_element)\n",
    "    #batch = next_element\n",
    "    # Get the next batch of images\n",
    "    #batch = mnist.train.next_batch(batch_size)\n",
    "    #batch = iter(mnist_train).get_next()\n",
    "    #image_batch, label_batch = batch(train_data)\n",
    "    # Print progress\n",
    "    if i % 50 == 0:\n",
    "        cur_accuracy = accuracy.eval(feed_dict = {\n",
    "                x: batch_x, y_loss: batch_y, keep_prob: 1.0})\n",
    "        print('Iteration', i, ', Accuracy =', cur_accuracy)\n",
    "\n",
    "    # Train on the current batch\n",
    "    optimizer.run(feed_dict = {x: batch_x, y_loss: batch_y, keep_prob: 0.5})\n",
    "\n",
    "# Compute accuracy using test data\n",
    "print('Test accuracy =', accuracy.eval(feed_dict = {\n",
    "        x: batch_x, y_loss: batch_y,\n",
    "        keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Import Handwritten Images </h3>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3> Import Handwritten Images </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to load handwritten data\n",
    "def load_images(image_label, image_directory, features_data,label_data):\n",
    "    files = os.listdir(image_directory)\n",
    "    for file in files:\n",
    "        image_file_name = os.path.join(image_directory, file)\n",
    "        if \".jpg\" in image_file_name:\n",
    "            img = Image.open(image_file_name).convert(\"L\")\n",
    "            img = np.resize(img, (28,28,1))\n",
    "            im2arr = np.array(img)\n",
    "            im2arr = im2arr.reshape(1,28,28,1)\n",
    "            features_data = np.append(features_data, im2arr,axis=0)\n",
    "            label_data = np.append(label_data,[image_label], axis=0)\n",
    "    return features_data, label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add files to new xTehand and yTehand\n",
    "xTehand = np.zeros((1,28,28,1))\n",
    "#xTehand = tf.placeholder(tf.float32, [None, 28, 28,1])\n",
    "yTehand = np.zeros((10))\n",
    "for i in range(1):\n",
    "    xTehand, yTehand = load_images(i, '.\\DataByHand', xTehand, yTehand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize inputs of xTehand\n",
    "xTehand/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.56470588],\n",
       "         [0.56470588],\n",
       "         [0.56470588],\n",
       "         ...,\n",
       "         [0.56470588],\n",
       "         [0.56470588],\n",
       "         [0.56470588]],\n",
       "\n",
       "        [[0.56470588],\n",
       "         [0.56470588],\n",
       "         [0.56470588],\n",
       "         ...,\n",
       "         [0.56862745],\n",
       "         [0.56862745],\n",
       "         [0.56862745]],\n",
       "\n",
       "        [[0.57254902],\n",
       "         [0.57254902],\n",
       "         [0.57254902],\n",
       "         ...,\n",
       "         [0.56862745],\n",
       "         [0.56862745],\n",
       "         [0.56862745]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.57254902],\n",
       "         [0.57254902],\n",
       "         [0.57254902],\n",
       "         ...,\n",
       "         [0.56862745],\n",
       "         [0.56862745],\n",
       "         [0.56862745]],\n",
       "\n",
       "        [[0.56862745],\n",
       "         [0.56862745],\n",
       "         [0.56862745],\n",
       "         ...,\n",
       "         [0.57254902],\n",
       "         [0.57647059],\n",
       "         [0.57647059]],\n",
       "\n",
       "        [[0.57647059],\n",
       "         [0.57647059],\n",
       "         [0.57647059],\n",
       "         ...,\n",
       "         [0.55686275],\n",
       "         [0.56078431],\n",
       "         [0.56470588]]],\n",
       "\n",
       "\n",
       "       [[[0.61176471],\n",
       "         [0.61176471],\n",
       "         [0.61176471],\n",
       "         ...,\n",
       "         [0.60392157],\n",
       "         [0.60392157],\n",
       "         [0.60392157]],\n",
       "\n",
       "        [[0.60392157],\n",
       "         [0.60392157],\n",
       "         [0.60392157],\n",
       "         ...,\n",
       "         [0.61568627],\n",
       "         [0.61568627],\n",
       "         [0.61568627]],\n",
       "\n",
       "        [[0.61960784],\n",
       "         [0.61568627],\n",
       "         [0.60784314],\n",
       "         ...,\n",
       "         [0.60784314],\n",
       "         [0.60784314],\n",
       "         [0.60784314]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.60392157],\n",
       "         [0.60392157],\n",
       "         [0.60392157],\n",
       "         ...,\n",
       "         [0.59215686],\n",
       "         [0.6       ],\n",
       "         [0.60392157]],\n",
       "\n",
       "        [[0.61960784],\n",
       "         [0.62352941],\n",
       "         [0.62352941],\n",
       "         ...,\n",
       "         [0.60392157],\n",
       "         [0.6       ],\n",
       "         [0.6       ]],\n",
       "\n",
       "        [[0.60392157],\n",
       "         [0.60784314],\n",
       "         [0.61176471],\n",
       "         ...,\n",
       "         [0.51372549],\n",
       "         [0.50980392],\n",
       "         [0.50980392]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.58431373],\n",
       "         [0.58039216],\n",
       "         [0.58039216],\n",
       "         ...,\n",
       "         [0.57647059],\n",
       "         [0.57647059],\n",
       "         [0.57647059]],\n",
       "\n",
       "        [[0.57647059],\n",
       "         [0.57647059],\n",
       "         [0.57647059],\n",
       "         ...,\n",
       "         [0.58039216],\n",
       "         [0.58039216],\n",
       "         [0.58039216]],\n",
       "\n",
       "        [[0.58039216],\n",
       "         [0.58039216],\n",
       "         [0.58039216],\n",
       "         ...,\n",
       "         [0.57647059],\n",
       "         [0.57647059],\n",
       "         [0.57647059]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.58039216],\n",
       "         [0.58039216],\n",
       "         [0.58039216],\n",
       "         ...,\n",
       "         [0.58823529],\n",
       "         [0.58823529],\n",
       "         [0.59215686]],\n",
       "\n",
       "        [[0.58431373],\n",
       "         [0.58431373],\n",
       "         [0.58431373],\n",
       "         ...,\n",
       "         [0.56862745],\n",
       "         [0.57254902],\n",
       "         [0.57647059]],\n",
       "\n",
       "        [[0.58431373],\n",
       "         [0.58823529],\n",
       "         [0.59215686],\n",
       "         ...,\n",
       "         [0.58823529],\n",
       "         [0.58823529],\n",
       "         [0.58823529]]],\n",
       "\n",
       "\n",
       "       [[[0.56470588],\n",
       "         [0.56470588],\n",
       "         [0.56470588],\n",
       "         ...,\n",
       "         [0.57254902],\n",
       "         [0.57254902],\n",
       "         [0.57254902]],\n",
       "\n",
       "        [[0.57254902],\n",
       "         [0.57254902],\n",
       "         [0.57254902],\n",
       "         ...,\n",
       "         [0.57254902],\n",
       "         [0.57254902],\n",
       "         [0.57254902]],\n",
       "\n",
       "        [[0.57254902],\n",
       "         [0.57254902],\n",
       "         [0.57254902],\n",
       "         ...,\n",
       "         [0.57254902],\n",
       "         [0.57254902],\n",
       "         [0.56862745]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.57647059],\n",
       "         [0.57647059],\n",
       "         [0.57647059],\n",
       "         ...,\n",
       "         [0.57254902],\n",
       "         [0.57254902],\n",
       "         [0.57254902]],\n",
       "\n",
       "        [[0.57254902],\n",
       "         [0.57254902],\n",
       "         [0.57254902],\n",
       "         ...,\n",
       "         [0.56862745],\n",
       "         [0.56862745],\n",
       "         [0.56862745]],\n",
       "\n",
       "        [[0.56862745],\n",
       "         [0.56862745],\n",
       "         [0.57254902],\n",
       "         ...,\n",
       "         [0.58431373],\n",
       "         [0.58431373],\n",
       "         [0.58431373]]],\n",
       "\n",
       "\n",
       "       [[[0.56470588],\n",
       "         [0.56470588],\n",
       "         [0.56470588],\n",
       "         ...,\n",
       "         [0.56862745],\n",
       "         [0.57647059],\n",
       "         [0.58039216]],\n",
       "\n",
       "        [[0.58039216],\n",
       "         [0.57647059],\n",
       "         [0.56862745],\n",
       "         ...,\n",
       "         [0.57254902],\n",
       "         [0.57254902],\n",
       "         [0.57254902]],\n",
       "\n",
       "        [[0.57254902],\n",
       "         [0.57254902],\n",
       "         [0.57254902],\n",
       "         ...,\n",
       "         [0.57254902],\n",
       "         [0.57254902],\n",
       "         [0.57254902]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.58039216],\n",
       "         [0.58039216],\n",
       "         [0.58039216],\n",
       "         ...,\n",
       "         [0.58039216],\n",
       "         [0.58039216],\n",
       "         [0.58039216]],\n",
       "\n",
       "        [[0.58039216],\n",
       "         [0.58039216],\n",
       "         [0.58039216],\n",
       "         ...,\n",
       "         [0.58431373],\n",
       "         [0.58431373],\n",
       "         [0.58431373]],\n",
       "\n",
       "        [[0.58823529],\n",
       "         [0.58823529],\n",
       "         [0.58823529],\n",
       "         ...,\n",
       "         [0.58823529],\n",
       "         [0.58823529],\n",
       "         [0.58823529]]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
